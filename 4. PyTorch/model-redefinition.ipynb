{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise a, b: 새로운 모델 적용\n",
    "\n",
    "이 파일은 기존의 코드에서 새로운 모델을 적용하여 수정한 파일이다.\n",
    "\n",
    "**Exercise a, b에 답하기 위해 사용된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 패키지 Import\n",
    "\n",
    "PyTorch 패키지를 Import 하고, 출력 형식을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 정의 (수정된 부분)\n",
    "\n",
    "기존의 모델($w \\times t_u + b$)에서 새로운 모델($w_2 \\times t_u^2 + w_1 \\times t_u + b$)로 코드를 수정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정: 새로운 모델 정의\n",
    "def model(t_u, w1, w2, b):\n",
    "    return (w2 * t_u ** 2) + (w1 * t_u) + b\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습을 위한 함수 정의\n",
    "\n",
    "`model` 함수에 맞게 파라미터를 최적화하는 과정을 정의한다. `model` 함수가 바뀌었음에도 `training_loop` 함수를 바뀌지 않았는데, 이는 PyTorch 라이브러리가 모델에 독립적으로 모든 Tensor에 대한 오차 역전파를 수행할 수 있도록 구현되었기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u,\n",
    "                  train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "                             \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                  f\" Validation loss {val_loss.item():.4f}\")\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터셋 준비\n",
    "\n",
    "데이터를 랜덤 셔플한 뒤 입력 데이터에 정규화를 시행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0,\n",
    "                    8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "t_u = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9,\n",
    "                    33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "                    \n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_t_u = t_u[train_indices]\n",
    "train_t_c = t_c[train_indices]\n",
    "\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 진행 (수정된 부분)\n",
    "\n",
    "기존의 `params` Tensor는 2차원이었으나, 새로운 모델은 3개의 파라미터가 필요하므로, `params`의 차원을 3차원으로 키웠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 46.7604, Validation loss 231.5821\n",
      "Epoch 2, Training loss 21.0734, Validation loss 84.9183\n",
      "Epoch 3, Training loss 17.4891, Validation loss 15.2917\n",
      "Epoch 500, Training loss 1.8162, Validation loss 12.3090\n",
      "Epoch 1000, Training loss 1.8035, Validation loss 10.8250\n",
      "Epoch 1500, Training loss 1.7994, Validation loss 9.8849\n",
      "Epoch 2000, Training loss 1.7988, Validation loss 9.4846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0717,  0.5533, -6.0193], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수정: 파라미터의 차원 수 조정\n",
    "params = torch.tensor([1.0, 0.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 2000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_t_u = train_t_un,\n",
    "    val_t_u = val_t_un,\n",
    "    train_t_c = train_t_c,\n",
    "    val_t_c = val_t_c)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d450bc581c61e6a6913694de69e42a9f9e6c85ec3badee7d8675ebbee8d92d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
